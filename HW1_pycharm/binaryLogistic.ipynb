{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import mnist\n",
    "import scipy\n",
    "import scipy.sparse.linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import identity\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST loaded\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = mnist.load_mnist(\"training\", None, './MNIST');\n",
    "testX, testY = mnist.load_mnist(\"testing\", None, './MNIST');\n",
    "print(\"MNIST loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainX = trainX[0:100, :]\n",
    "#trainY = trainY[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logistic:\n",
    "    \n",
    "    \n",
    "    def __init__(self, eta, lamda, thresh):\n",
    "        self.eta = eta;\n",
    "        self.lamda = lamda;\n",
    "        self.thresh = thresh;\n",
    "        self.regularized = True;\n",
    "        self.lossSet = np.zeros(2000);\n",
    "        self.testLossSet = np.zeros(2000);\n",
    "        \n",
    "    def load_data(self, string, ori_X, ori_Y):\n",
    "        \"\"\"\n",
    "        if string is \"training\":\n",
    "            ori_X, self.Y = mnist.load_mnist(\"training\", None, './MNIST');\n",
    "        elif string is \"testing\":\n",
    "            ori_X, self.Y = mnist.load_mnist(\"testing\", None, './MNIST');\n",
    "        \"\"\"\n",
    "        self.Y = ori_Y;\n",
    "        s = ori_X.shape;\n",
    "        self.d = s[1] * s[2] + 1;\n",
    "        self.n = self.d;\n",
    "        self.N = s[0];\n",
    "        self.X = np.reshape(ori_X, (self.N, self.d-1));\n",
    "        self.X = np.insert(self.X, 0, 1, axis=1);\n",
    "        self.X_sparse = csr_matrix(self.X, shape=(self.N, self.d))\n",
    "        print(\"Loading data \" + string + \" complete....\")\n",
    "        \n",
    "    def load_test(self, testX, testY):\n",
    "        self.testN = testX.shape[0];\n",
    "        self.testX = np.reshape(testX, (self.testN, self.d-1));\n",
    "        self.testX = np.insert(self.testX, 0, 1, axis=1);\n",
    "        self.testY = testY\n",
    "        \n",
    "    def makeTestY(self, val):\n",
    "        temp = np.array(self.testY == val, dtype=float);\n",
    "        self.testY = np.reshape(temp, (self.testN, 1))\n",
    "        print(\"Only looking at class \" + str(val) + \"!!!\")\n",
    "        \n",
    "    def makeY(self, val):\n",
    "        temp = np.array(self.Y == val, dtype=float);\n",
    "        self.Y = np.reshape(temp, (self.N, 1))\n",
    "        self.Y_sparse = csr_matrix(self.Y, shape=(self.N, 1))\n",
    "        print(\"Testing Data : Only looking at class \" + str(val) + \"!!!\")\n",
    "    \n",
    "    def initIteration(self):\n",
    "        self.weights = np.zeros((self.n,1), dtype=float);\n",
    "        self.iter = 0;\n",
    "        self.prevLoss = 999999;\n",
    "        self.weightDist = 99999;\n",
    "    \n",
    "    def computeTestLoss(self):\n",
    "        temp = np.dot(self.testX, self.weights);\n",
    "        temp[temp>100] = 100\n",
    "        temp = np.exp(temp);\n",
    "        self.prob1Test = temp / (1 + temp)\n",
    "        self.sampleTestLoss = self.testY - self.prob1Test; \n",
    "        lttemp = np.concatenate([np.float64(self.testY==0), np.float64(self.testY==1)], axis=1);\n",
    "        rttemp = np.asarray(np.concatenate([1-self.prob1Test, self.prob1Test], axis=1))\n",
    "        self.testLoss = -np.sum(np.log(np.sum(lttemp * rttemp, axis=1) + 0.0000001)) / self.testN + self.lamda * np.linalg.norm(self.weights); \n",
    "        self.testLossSet[self.iter]=self.testLoss\n",
    "    \n",
    "    def computeProb1(self):\n",
    "        temp = np.dot(self.X, self.weights);\n",
    "        temp[temp>100] = 100\n",
    "        temp = np.exp(temp);\n",
    "        self.prob1 = temp / (1 + temp)\n",
    "        self.sampleLoss = self.Y - self.prob1; \n",
    "        \n",
    "    def computeLoss(self):\n",
    "        \n",
    "        #self.loss = np.sqrt(np.sum(self.sampleLoss * self.sampleLoss) / self.N)\n",
    "        lttemp = np.concatenate([np.float64(self.Y==0), np.float64(self.Y==1)], axis=1);\n",
    "        rttemp = np.asarray(np.concatenate([1-self.prob1, self.prob1], axis=1))\n",
    "        self.loss = -np.sum(np.log(np.sum(lttemp * rttemp, axis=1) + 0.0000001)) / self.N + self.lamda * np.linalg.norm(self.weights); \n",
    "        self.lossSet[self.iter]=self.loss\n",
    "    \n",
    "    def updateWeights(self, curIdx, batchSize):\n",
    "        #print('Weight ' + str(curIdx) + ' : ' + str(self.weights[curIdx]))\n",
    "        self.batchSize = batchSize;\n",
    "        idx_from = range(0, self.N, self.batchSize)\n",
    "        idx_to = idx_from[1:]\n",
    "        idx_to.extend([self.N])\n",
    "        \n",
    "        if self.regularized:\n",
    "            for x in range(0, len(idx_from)):\n",
    "                self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[idx_from[x]:idx_to[x], curIdx] * self.sampleLoss[idx_from[x]:idx_to[x],0]);\n",
    "            self.weights[curIdx] = self.weights[curIdx] - self.eta * self.weights[curIdx] * self.lamda;\n",
    "            #self.weights[curIdx] = self.weights[curIdx] + self.eta * (np.sum(self.X[:, curIdx] * self.sampleLoss[:,0]) - self.weights[curIdx] * self.lamda);\n",
    "        else:\n",
    "            for x in range(0, len(idx_from)):\n",
    "                self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[idx_from[x]:idx_to[x], curIdx] * self.sampleLoss[idx_from[x]:idx_to[x],0]);\n",
    "            #self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[:, curIdx] * self.sampleLoss[:,0]);\n",
    "        #print('Weight ' + str(curIdx) + ' : ' + str(self.weights[curIdx]))\n",
    "        \n",
    "    def updateWeightsWhole(self, batchSize):\n",
    "        self.batchSize = batchSize;\n",
    "        idx_from = range(0, self.N, self.batchSize)\n",
    "        idx_to = idx_from[1:]\n",
    "        idx_to.extend([self.N])\n",
    "        \n",
    "        if self.regularized:\n",
    "            #for x in range(0, len(idx_from)):\n",
    "            #    self.weights = self.weights + self.eta * np.asmatrix(self.X[idx_from[x]:idx_to[x], :].transpose()) * np.asmatrix(self.sampleLoss[idx_from[x]:idx_to[x],:]) / (self.N);\n",
    "            #pdb.set_trace();\n",
    "            self.weights = self.weights + self.eta * np.asmatrix(self.X.transpose()) * np.asmatrix(self.sampleLoss) / (self.N);\n",
    "            self.weights = self.weights - self.eta * self.weights * self.lamda;\n",
    "            #self.weights = self.weights - self.eta * np.linalg.norm(self.weights[1:self.n]) * self.lamda;\n",
    "            #self.weights[curIdx] = self.weights[curIdx] + self.eta * (np.sum(self.X[:, curIdx] * self.sampleLoss[:,0]) - self.weights[curIdx] * self.lamda);\n",
    "        else:\n",
    "            for x in range(0, len(idx_from)):\n",
    "                self.weights = self.weights + self.eta * np.asmatrix(self.X[idx_from[x]:idx_to[x], :].transpose()) * self.sampleLoss[idx_from[x]:idx_to[x],:];\n",
    "            #self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[:, curIdx] * self.sampleLoss[:,0]);\n",
    "        #print('Weight ' + str(curIdx) + ' : ' + str(self.weights[curIdx]))\n",
    "    \n",
    "    \n",
    "    def distWeight(self, A, B):\n",
    "        self.weightDist = scipy.linalg.norm(A - B);\n",
    "        \n",
    "        print(\"weight distance : \" + str(self.weightDist));\n",
    "    \n",
    "    def updateWeightStochastic(self, curIdx, curSmp):\n",
    "        if self.regularized:\n",
    "            self.weights[curIdx] = self.weights[curIdx] + self.eta * (self.X[curSmp, curIdx] * self.sampleLoss[curSmp,0] - self.weights[curIdx] * self.lamda);\n",
    "        else:\n",
    "            self.weights[curIdx] = self.weights[curIdx] + self.eta * self.X[curSmp, curIdx] * self.sampleLoss[curSmp,0];\n",
    "    \n",
    "    def assess(self):\n",
    "        self.computeProb1();\n",
    "        self.pred = self.prob1 > 0.5;\n",
    "        self.correct = np.sum(np.int16(self.pred == (self.Y==1)))\n",
    "        self.overallAccu = np.float(self.correct) / np.float(self.N);\n",
    "        self.loss01 = sum(abs(self.pred - self.Y)) / self.N\n",
    "        print('Accuracy : ' + str(self.overallAccu))\n",
    "        print('0 / 1 loss : ' + str(self.loss01))\n",
    "    \n",
    "    def genGaussFeatWeight(self, n):\n",
    "        self.n = n;\n",
    "        self.weight = np.random.randn(self.d, self.n);\n",
    "    \n",
    "    def randGaussFeatConv(self):\n",
    "        self.X = np.dot(self.X, self.weight);\n",
    "        \n",
    "    def plotLoss(self, labelTrain, labelTest, name):\n",
    "        %matplotlib inline \n",
    "        matplotlib.pyplot.plot(np.arange(0, model.iter), model.testLossSet[0:model.iter], hold = True, color=\"blue\", linewidth=2.0)\n",
    "        matplotlib.pyplot.plot(np.arange(0, model.iter), model.lossSet[0:model.iter], hold = True, color=\"red\", linewidth=2.0)\n",
    "        matplotlib.pyplot.savefig(name, transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data training complete....\n",
      "Testing Data : Only looking at class 2!!!\n",
      "Only looking at class 2!!!\n"
     ]
    }
   ],
   "source": [
    "model = logistic(0.1, 0.01, 0.00001);\n",
    "model.load_data(\"training\", trainX, trainY);\n",
    "model.load_test(testX, testY)\n",
    "model.makeY(2);\n",
    "model.makeTestY(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : Loss value 0.69314698056\n",
      "weight distance : 0.237977236008\n",
      "Iteration 1 : Loss value 0.37356346001\n",
      "weight distance : 0.0558246394994\n",
      "Iteration 2 : Loss value 0.348425577372\n",
      "weight distance : 0.0380122870115\n",
      "Iteration 3 : Loss value 0.335502204165\n",
      "weight distance : 0.0319848496934\n",
      "Iteration 4 : Loss value 0.325890323568\n",
      "weight distance : 0.029365456615\n",
      "Iteration 5 : Loss value 0.317613636821\n",
      "weight distance : 0.0279241668346\n",
      "Iteration 6 : Loss value 0.3100641063\n",
      "weight distance : 0.0269288053988\n",
      "Iteration 7 : Loss value 0.303020088864\n",
      "weight distance : 0.0261144694432\n",
      "Iteration 8 : Loss value 0.296389190885\n",
      "weight distance : 0.0253797397522\n",
      "Iteration 9 : Loss value 0.29012617324\n",
      "weight distance : 0.0246849053895\n",
      "Iteration 10 : Loss value 0.284203686178\n",
      "weight distance : 0.0240147189307\n",
      "Iteration 11 : Loss value 0.278601233288\n",
      "weight distance : 0.0233638429327\n",
      "Iteration 12 : Loss value 0.273300956267\n",
      "weight distance : 0.0227309011951\n",
      "Iteration 13 : Loss value 0.26828608383\n",
      "weight distance : 0.0221159868353\n",
      "Iteration 14 : Loss value 0.263540430892\n",
      "weight distance : 0.0215196169553\n",
      "Iteration 15 : Loss value 0.25904829892\n",
      "weight distance : 0.0209423079936\n",
      "Iteration 16 : Loss value 0.25479451378\n",
      "weight distance : 0.0203844198806\n",
      "Iteration 17 : Loss value 0.250764496\n",
      "weight distance : 0.0198461155339\n",
      "Iteration 18 : Loss value 0.246944324289\n",
      "weight distance : 0.0193273679666\n",
      "Iteration 19 : Loss value 0.24332078029\n",
      "weight distance : 0.0188279850969\n",
      "Iteration 20 : Loss value 0.23988137324\n",
      "weight distance : 0.018347639213\n",
      "Iteration 21 : Loss value 0.236614347059\n",
      "weight distance : 0.0178858956036\n",
      "Iteration 22 : Loss value 0.233508673378\n",
      "weight distance : 0.0174422382372\n",
      "Iteration 23 : Loss value 0.230554033951\n",
      "weight distance : 0.0170160918698\n",
      "Iteration 24 : Loss value 0.227740795422\n",
      "weight distance : 0.0166068406028\n",
      "Iteration 25 : Loss value 0.22505997889\n",
      "weight distance : 0.0162138431792\n",
      "Iteration 26 : Loss value 0.222503226199\n",
      "weight distance : 0.0158364453983\n",
      "Iteration 27 : Loss value 0.22006276447\n",
      "weight distance : 0.0154739900393\n",
      "Iteration 28 : Loss value 0.217731370015\n",
      "weight distance : 0.0151258246726\n",
      "Iteration 29 : Loss value 0.215502332464\n",
      "weight distance : 0.0147913076944\n",
      "Iteration 30 : Loss value 0.213369419751\n",
      "weight distance : 0.0144698128891\n",
      "Iteration 31 : Loss value 0.21132684436\n",
      "weight distance : 0.0141607327804\n",
      "Iteration 32 : Loss value 0.209369231138\n",
      "weight distance : 0.0138634809963\n",
      "Iteration 33 : Loss value 0.207491586833\n",
      "weight distance : 0.0135774938388\n",
      "Iteration 34 : Loss value 0.205689271471\n",
      "weight distance : 0.0133022312187\n",
      "Iteration 35 : Loss value 0.203957971581\n",
      "weight distance : 0.0130371770893\n",
      "Iteration 36 : Loss value 0.202293675257\n",
      "weight distance : 0.0127818394893\n",
      "Iteration 37 : Loss value 0.20069264902\n",
      "weight distance : 0.0125357502853\n",
      "Iteration 38 : Loss value 0.199151416388\n",
      "weight distance : 0.0122984646878\n",
      "Iteration 39 : Loss value 0.197666738095\n",
      "weight distance : 0.012069560601\n",
      "Iteration 40 : Loss value 0.196235593834\n",
      "weight distance : 0.011848637853\n",
      "Iteration 41 : Loss value 0.194855165458\n",
      "weight distance : 0.0116353173459\n",
      "Iteration 42 : Loss value 0.193522821512\n",
      "weight distance : 0.0114292401555\n",
      "Iteration 43 : Loss value 0.192236103026\n",
      "weight distance : 0.0112300666038\n",
      "Iteration 44 : Loss value 0.190992710445\n",
      "weight distance : 0.0110374753239\n",
      "Iteration 45 : Loss value 0.189790491641\n",
      "weight distance : 0.0108511623299\n",
      "Iteration 46 : Loss value 0.188627430884\n",
      "weight distance : 0.0106708401033\n",
      "Iteration 47 : Loss value 0.18750163873\n",
      "weight distance : 0.0104962367033\n",
      "Iteration 48 : Loss value 0.186411342718\n",
      "weight distance : 0.0103270949071\n",
      "Iteration 49 : Loss value 0.185354878835\n",
      "weight distance : 0.0101631713829\n",
      "Iteration 50 : Loss value 0.184330683666\n",
      "weight distance : 0.0100042358994\n",
      "Iteration 51 : Loss value 0.183337287181\n",
      "weight distance : 0.00985007057178\n",
      "Iteration 52 : Loss value 0.182373306094\n",
      "weight distance : 0.00970046914649\n",
      "Iteration 53 : Loss value 0.181437437764\n",
      "weight distance : 0.00955523632244\n",
      "Iteration 54 : Loss value 0.180528454571\n",
      "weight distance : 0.00941418711\n",
      "Iteration 55 : Loss value 0.179645198738\n",
      "weight distance : 0.00927714622584\n",
      "Iteration 56 : Loss value 0.17878657756\n",
      "weight distance : 0.00914394752269\n",
      "Iteration 57 : Loss value 0.177951559003\n",
      "weight distance : 0.00901443345268\n",
      "Iteration 58 : Loss value 0.177139167639\n",
      "weight distance : 0.00888845456266\n",
      "Iteration 59 : Loss value 0.176348480904\n",
      "weight distance : 0.00876586902019\n",
      "Iteration 60 : Loss value 0.17557862562\n",
      "weight distance : 0.00864654216833\n",
      "Iteration 61 : Loss value 0.1748287748\n",
      "weight distance : 0.00853034610795\n",
      "Iteration 62 : Loss value 0.174098144681\n",
      "weight distance : 0.00841715930586\n",
      "Iteration 63 : Loss value 0.17338599197\n",
      "weight distance : 0.00830686622726\n",
      "Iteration 64 : Loss value 0.172691611312\n",
      "weight distance : 0.00819935699117\n",
      "Iteration 65 : Loss value 0.172014332918\n",
      "weight distance : 0.00809452704729\n",
      "Iteration 66 : Loss value 0.171353520384\n",
      "weight distance : 0.00799227687305\n",
      "Iteration 67 : Loss value 0.170708568655\n",
      "weight distance : 0.00789251168962\n",
      "Iteration 68 : Loss value 0.170078902133\n",
      "weight distance : 0.00779514119557\n",
      "Iteration 69 : Loss value 0.169463972926\n",
      "weight distance : 0.00770007931707\n",
      "Iteration 70 : Loss value 0.168863259207\n",
      "weight distance : 0.00760724397369\n",
      "Iteration 71 : Loss value 0.168276263694\n",
      "weight distance : 0.00751655685855\n",
      "Iteration 72 : Loss value 0.167702512234\n",
      "weight distance : 0.00742794323216\n",
      "Iteration 73 : Loss value 0.167141552475\n",
      "weight distance : 0.00734133172883\n",
      "Iteration 74 : Loss value 0.166592952637\n",
      "weight distance : 0.0072566541749\n",
      "Iteration 75 : Loss value 0.166056300356\n",
      "weight distance : 0.0071738454181\n",
      "Iteration 76 : Loss value 0.165531201608\n",
      "weight distance : 0.00709284316722\n",
      "Iteration 77 : Loss value 0.165017279703\n",
      "weight distance : 0.00701358784135\n",
      "Iteration 78 : Loss value 0.164514174342\n",
      "weight distance : 0.0069360224283\n",
      "Iteration 79 : Loss value 0.164021540737\n",
      "weight distance : 0.00686009235129\n",
      "Iteration 80 : Loss value 0.163539048785\n",
      "weight distance : 0.00678574534368\n",
      "Iteration 81 : Loss value 0.16306638229\n",
      "weight distance : 0.00671293133098\n",
      "Iteration 82 : Loss value 0.162603238243\n",
      "weight distance : 0.00664160231978\n",
      "Iteration 83 : Loss value 0.162149326135\n",
      "weight distance : 0.00657171229315\n",
      "Iteration 84 : Loss value 0.161704367323\n",
      "weight distance : 0.00650321711208\n",
      "Iteration 85 : Loss value 0.161268094421\n",
      "weight distance : 0.00643607442257\n",
      "Iteration 86 : Loss value 0.160840250744\n",
      "weight distance : 0.006370243568\n",
      "Iteration 87 : Loss value 0.160420589769\n",
      "weight distance : 0.0063056855065\n",
      "Iteration 88 : Loss value 0.160008874638\n",
      "weight distance : 0.00624236273294\n",
      "Iteration 89 : Loss value 0.159604877684\n",
      "weight distance : 0.00618023920526\n",
      "Iteration 90 : Loss value 0.159208379994\n",
      "weight distance : 0.00611928027495\n",
      "Iteration 91 : Loss value 0.158819170979\n",
      "weight distance : 0.00605945262129\n",
      "Iteration 92 : Loss value 0.158437047991\n",
      "weight distance : 0.00600072418923\n",
      "Iteration 93 : Loss value 0.158061815941\n",
      "weight distance : 0.00594306413064\n",
      "Iteration 94 : Loss value 0.157693286953\n",
      "weight distance : 0.0058864427487\n",
      "Iteration 95 : Loss value 0.157331280029\n",
      "weight distance : 0.00583083144534\n",
      "Iteration 96 : Loss value 0.156975620735\n",
      "weight distance : 0.00577620267136\n",
      "Iteration 97 : Loss value 0.156626140904\n",
      "weight distance : 0.00572252987933\n",
      "Iteration 98 : Loss value 0.156282678354\n",
      "weight distance : 0.00566978747884\n",
      "Iteration 99 : Loss value 0.155945076625\n",
      "weight distance : 0.00561795079412\n",
      "Iteration 100 : Loss value 0.155613184723\n",
      "weight distance : 0.0055669960239\n",
      "Iteration 101 : Loss value 0.155286856882\n",
      "weight distance : 0.00551690020326\n",
      "Iteration 102 : Loss value 0.15496595234\n",
      "weight distance : 0.00546764116744\n",
      "Iteration 103 : Loss value 0.154650335121\n",
      "weight distance : 0.00541919751755\n",
      "Iteration 104 : Loss value 0.154339873833\n",
      "weight distance : 0.00537154858787\n",
      "Iteration 105 : Loss value 0.154034441476\n",
      "weight distance : 0.00532467441496\n",
      "Iteration 106 : Loss value 0.153733915255\n",
      "weight distance : 0.00527855570812\n",
      "Iteration 107 : Loss value 0.153438176406\n",
      "weight distance : 0.00523317382144\n",
      "Iteration 108 : Loss value 0.153147110035\n",
      "weight distance : 0.00518851072714\n",
      "Iteration 109 : Loss value 0.152860604954\n",
      "weight distance : 0.00514454899025\n",
      "Iteration 110 : Loss value 0.152578553533\n",
      "weight distance : 0.00510127174445\n",
      "Iteration 111 : Loss value 0.152300851559\n",
      "weight distance : 0.00505866266917\n",
      "Iteration 112 : Loss value 0.1520273981\n",
      "weight distance : 0.00501670596763\n",
      "Iteration 113 : Loss value 0.151758095371\n",
      "weight distance : 0.00497538634607\n",
      "Iteration 114 : Loss value 0.151492848617\n",
      "weight distance : 0.00493468899386\n",
      "Iteration 115 : Loss value 0.151231565992\n",
      "weight distance : 0.00489459956455\n",
      "Iteration 116 : Loss value 0.150974158446\n",
      "weight distance : 0.00485510415782\n",
      "Iteration 117 : Loss value 0.150720539621\n",
      "weight distance : 0.00481618930224\n",
      "Iteration 118 : Loss value 0.150470625746\n",
      "weight distance : 0.0047778419388\n",
      "Iteration 119 : Loss value 0.150224335541\n",
      "weight distance : 0.00474004940526\n",
      "Iteration 120 : Loss value 0.149981590126\n",
      "weight distance : 0.00470279942109\n",
      "Iteration 121 : Loss value 0.149742312928\n",
      "weight distance : 0.00466608007319\n",
      "Iteration 122 : Loss value 0.149506429599\n",
      "weight distance : 0.00462987980217\n",
      "Iteration 123 : Loss value 0.149273867935\n",
      "weight distance : 0.00459418738928\n",
      "Iteration 124 : Loss value 0.149044557794\n",
      "weight distance : 0.00455899194388\n",
      "Iteration 125 : Loss value 0.14881843103\n",
      "weight distance : 0.00452428289148\n",
      "Iteration 126 : Loss value 0.148595421413\n",
      "weight distance : 0.0044900499623\n",
      "Iteration 127 : Loss value 0.148375464568\n",
      "weight distance : 0.00445628318027\n",
      "Iteration 128 : Loss value 0.148158497907\n",
      "weight distance : 0.00442297285259\n",
      "Iteration 129 : Loss value 0.147944460563\n",
      "weight distance : 0.00439010955962\n",
      "Iteration 130 : Loss value 0.14773329334\n",
      "weight distance : 0.00435768414532\n",
      "Iteration 131 : Loss value 0.147524938644\n",
      "weight distance : 0.00432568770797\n",
      "Iteration 132 : Loss value 0.147319340437\n",
      "weight distance : 0.00429411159135\n",
      "Iteration 133 : Loss value 0.14711644418\n",
      "weight distance : 0.00426294737629\n",
      "Iteration 134 : Loss value 0.146916196785\n",
      "weight distance : 0.00423218687252\n",
      "Iteration 135 : Loss value 0.146718546565\n",
      "weight distance : 0.00420182211084\n",
      "Iteration 136 : Loss value 0.146523443185\n",
      "weight distance : 0.00417184533572\n",
      "Iteration 137 : Loss value 0.146330837623\n",
      "weight distance : 0.00414224899805\n",
      "Iteration 138 : Loss value 0.146140682124\n",
      "weight distance : 0.00411302574828\n",
      "Iteration 139 : Loss value 0.145952930157\n",
      "weight distance : 0.00408416842979\n",
      "Iteration 140 : Loss value 0.145767536379\n",
      "weight distance : 0.00405567007256\n",
      "Iteration 141 : Loss value 0.145584456596\n",
      "weight distance : 0.00402752388701\n",
      "Iteration 142 : Loss value 0.145403647724\n",
      "weight distance : 0.00399972325818\n",
      "Iteration 143 : Loss value 0.145225067756\n",
      "weight distance : 0.00397226174007\n",
      "Iteration 144 : Loss value 0.145048675729\n",
      "weight distance : 0.00394513305023\n",
      "Iteration 145 : Loss value 0.144874431689\n",
      "weight distance : 0.00391833106449\n",
      "Iteration 146 : Loss value 0.14470229666\n",
      "weight distance : 0.00389184981203\n",
      "Iteration 147 : Loss value 0.144532232618\n",
      "weight distance : 0.00386568347048\n",
      "Iteration 148 : Loss value 0.144364202455\n",
      "weight distance : 0.00383982636129\n",
      "Iteration 149 : Loss value 0.144198169956\n",
      "weight distance : 0.00381427294529\n",
      "Iteration 150 : Loss value 0.144034099772\n",
      "weight distance : 0.00378901781834\n",
      "Iteration 151 : Loss value 0.143871957392\n",
      "weight distance : 0.00376405570721\n",
      "Iteration 152 : Loss value 0.143711709117\n",
      "weight distance : 0.00373938146556\n",
      "Iteration 153 : Loss value 0.14355332204\n",
      "weight distance : 0.00371499007013\n",
      "Iteration 154 : Loss value 0.143396764018\n",
      "weight distance : 0.00369087661698\n",
      "Iteration 155 : Loss value 0.143242003655\n",
      "weight distance : 0.00366703631797\n",
      "Iteration 156 : Loss value 0.143089010275\n",
      "weight distance : 0.00364346449726\n",
      "Iteration 157 : Loss value 0.142937753904\n",
      "weight distance : 0.00362015658801\n",
      "Iteration 158 : Loss value 0.142788205248\n",
      "weight distance : 0.00359710812917\n",
      "Iteration 159 : Loss value 0.142640335676\n",
      "weight distance : 0.0035743147624\n",
      "Iteration 160 : Loss value 0.1424941172\n",
      "weight distance : 0.00355177222906\n",
      "Iteration 161 : Loss value 0.142349522456\n",
      "weight distance : 0.00352947636735\n",
      "Iteration 162 : Loss value 0.142206524688\n",
      "weight distance : 0.00350742310949\n",
      "Iteration 163 : Loss value 0.14206509773\n",
      "weight distance : 0.00348560847909\n",
      "Iteration 164 : Loss value 0.141925215989\n",
      "weight distance : 0.00346402858852\n",
      "Iteration 165 : Loss value 0.141786854432\n",
      "weight distance : 0.00344267963641\n",
      "Iteration 166 : Loss value 0.141649988567\n",
      "weight distance : 0.00342155790524\n",
      "Iteration 167 : Loss value 0.141514594431\n",
      "weight distance : 0.00340065975897\n",
      "Iteration 168 : Loss value 0.141380648575\n",
      "weight distance : 0.00337998164082\n",
      "Iteration 169 : Loss value 0.141248128048\n",
      "weight distance : 0.00335952007108\n",
      "Iteration 170 : Loss value 0.141117010387\n",
      "weight distance : 0.00333927164494\n",
      "Iteration 171 : Loss value 0.140987273603\n",
      "weight distance : 0.00331923303054\n",
      "Iteration 172 : Loss value 0.140858896168\n",
      "weight distance : 0.00329940096691\n",
      "Iteration 173 : Loss value 0.140731857\n",
      "weight distance : 0.0032797722621\n",
      "Iteration 174 : Loss value 0.140606135457\n",
      "weight distance : 0.00326034379132\n",
      "Iteration 175 : Loss value 0.140481711322\n",
      "weight distance : 0.00324111249515\n",
      "Iteration 176 : Loss value 0.140358564792\n",
      "weight distance : 0.00322207537781\n",
      "Iteration 177 : Loss value 0.140236676469\n",
      "weight distance : 0.00320322950549\n",
      "Iteration 178 : Loss value 0.140116027348\n",
      "weight distance : 0.00318457200469\n",
      "Iteration 179 : Loss value 0.139996598808\n",
      "weight distance : 0.0031661000607\n",
      "Iteration 180 : Loss value 0.139878372601\n",
      "weight distance : 0.00314781091602\n",
      "Iteration 181 : Loss value 0.139761330844\n",
      "weight distance : 0.00312970186895\n",
      "Iteration 182 : Loss value 0.139645456009\n",
      "weight distance : 0.00311177027207\n",
      "Iteration 183 : Loss value 0.139530730915\n",
      "weight distance : 0.00309401353095\n",
      "Iteration 184 : Loss value 0.13941713872\n",
      "weight distance : 0.00307642910275\n",
      "Iteration 185 : Loss value 0.139304662908\n",
      "weight distance : 0.00305901449491\n",
      "Iteration 186 : Loss value 0.139193287287\n",
      "weight distance : 0.00304176726393\n",
      "Iteration 187 : Loss value 0.139082995979\n",
      "weight distance : 0.00302468501412\n",
      "Iteration 188 : Loss value 0.13897377341\n",
      "weight distance : 0.00300776539638\n",
      "Iteration 189 : Loss value 0.138865604307\n",
      "weight distance : 0.00299100610714\n",
      "Iteration 190 : Loss value 0.138758473685\n",
      "weight distance : 0.00297440488713\n",
      "Iteration 191 : Loss value 0.138652366847\n",
      "weight distance : 0.00295795952039\n",
      "Iteration 192 : Loss value 0.138547269371\n",
      "weight distance : 0.00294166783314\n",
      "Iteration 193 : Loss value 0.138443167107\n",
      "weight distance : 0.00292552769283\n",
      "Iteration 194 : Loss value 0.13834004617\n",
      "weight distance : 0.00290953700708\n",
      "Iteration 195 : Loss value 0.138237892933\n",
      "weight distance : 0.00289369372278\n",
      "Iteration 196 : Loss value 0.138136694022\n",
      "weight distance : 0.00287799582511\n",
      "Iteration 197 : Loss value 0.138036436308\n",
      "weight distance : 0.00286244133665\n",
      "Iteration 198 : Loss value 0.137937106905\n",
      "weight distance : 0.00284702831648\n",
      "Iteration 199 : Loss value 0.13783869316\n",
      "weight distance : 0.00283175485937\n",
      "Iteration 200 : Loss value 0.137741182652\n",
      "weight distance : 0.00281661909488\n",
      "Iteration 201 : Loss value 0.137644563184\n",
      "weight distance : 0.0028016191866\n",
      "Iteration 202 : Loss value 0.137548822778\n",
      "weight distance : 0.00278675333136\n",
      "Iteration 203 : Loss value 0.137453949671\n",
      "weight distance : 0.00277201975843\n",
      "Iteration 204 : Loss value 0.13735993231\n",
      "weight distance : 0.00275741672883\n",
      "Iteration 205 : Loss value 0.137266759347\n",
      "weight distance : 0.00274294253456\n",
      "Iteration 206 : Loss value 0.137174419634\n",
      "weight distance : 0.00272859549791\n",
      "Iteration 207 : Loss value 0.137082902221\n",
      "weight distance : 0.0027143739708\n",
      "Iteration 208 : Loss value 0.136992196347\n",
      "weight distance : 0.00270027633408\n",
      "Iteration 209 : Loss value 0.136902291441\n",
      "weight distance : 0.00268630099691\n",
      "Iteration 210 : Loss value 0.136813177114\n",
      "weight distance : 0.00267244639614\n",
      "Iteration 211 : Loss value 0.136724843158\n",
      "weight distance : 0.00265871099564\n",
      "Iteration 212 : Loss value 0.136637279538\n",
      "weight distance : 0.00264509328576\n",
      "Iteration 213 : Loss value 0.136550476394\n",
      "weight distance : 0.00263159178275\n",
      "Iteration 214 : Loss value 0.136464424032\n",
      "weight distance : 0.00261820502817\n",
      "Iteration 215 : Loss value 0.136379112924\n",
      "weight distance : 0.00260493158832\n",
      "Iteration 216 : Loss value 0.136294533701\n",
      "weight distance : 0.00259177005378\n",
      "Iteration 217 : Loss value 0.136210677154\n",
      "weight distance : 0.00257871903881\n",
      "Iteration 218 : Loss value 0.136127534226\n",
      "weight distance : 0.00256577718089\n",
      "Iteration 219 : Loss value 0.136045096014\n",
      "weight distance : 0.0025529431402\n",
      "Iteration 220 : Loss value 0.135963353761\n",
      "weight distance : 0.00254021559916\n",
      "Iteration 221 : Loss value 0.135882298854\n",
      "weight distance : 0.00252759326195\n",
      "Iteration 222 : Loss value 0.135801922824\n",
      "weight distance : 0.00251507485402\n",
      "Iteration 223 : Loss value 0.13572221734\n",
      "weight distance : 0.00250265912173\n",
      "Iteration 224 : Loss value 0.135643174207\n",
      "weight distance : 0.00249034483182\n",
      "Iteration 225 : Loss value 0.135564785363\n",
      "weight distance : 0.00247813077105\n",
      "Iteration 226 : Loss value 0.135487042877\n",
      "weight distance : 0.00246601574576\n",
      "Iteration 227 : Loss value 0.135409938946\n",
      "weight distance : 0.00245399858146\n",
      "Iteration 228 : Loss value 0.135333465893\n",
      "weight distance : 0.00244207812248\n",
      "Iteration 229 : Loss value 0.135257616162\n",
      "weight distance : 0.00243025323154\n",
      "Iteration 230 : Loss value 0.13518238232\n",
      "weight distance : 0.0024185227894\n",
      "Iteration 231 : Loss value 0.135107757049\n",
      "weight distance : 0.00240688569448\n",
      "Iteration 232 : Loss value 0.13503373315\n",
      "weight distance : 0.00239534086255\n",
      "Iteration 233 : Loss value 0.134960303533\n",
      "weight distance : 0.0023838872263\n",
      "Iteration 234 : Loss value 0.134887461224\n",
      "weight distance : 0.0023725237351\n",
      "Iteration 235 : Loss value 0.134815199355\n",
      "weight distance : 0.00236124935459\n",
      "Iteration 236 : Loss value 0.134743511165\n",
      "weight distance : 0.00235006306642\n",
      "Iteration 237 : Loss value 0.134672389998\n",
      "weight distance : 0.00233896386787\n",
      "Iteration 238 : Loss value 0.134601829302\n",
      "weight distance : 0.00232795077161\n",
      "Iteration 239 : Loss value 0.134531822624\n",
      "weight distance : 0.00231702280536\n",
      "Iteration 240 : Loss value 0.13446236361\n",
      "weight distance : 0.0023061790116\n",
      "Iteration 241 : Loss value 0.134393446004\n",
      "weight distance : 0.00229541844731\n",
      "Iteration 242 : Loss value 0.134325063645\n",
      "weight distance : 0.00228474018367\n",
      "Iteration 243 : Loss value 0.134257210464\n",
      "weight distance : 0.00227414330577\n",
      "Iteration 244 : Loss value 0.134189880484\n",
      "weight distance : 0.0022636269124\n",
      "Iteration 245 : Loss value 0.134123067819\n",
      "weight distance : 0.00225319011572\n",
      "Iteration 246 : Loss value 0.134056766669\n",
      "weight distance : 0.00224283204108\n",
      "Iteration 247 : Loss value 0.133990971322\n",
      "weight distance : 0.00223255182671\n",
      "Iteration 248 : Loss value 0.133925676151\n",
      "weight distance : 0.00222234862352\n",
      "Iteration 249 : Loss value 0.133860875611\n",
      "weight distance : 0.00221222159482\n",
      "Iteration 250 : Loss value 0.133796564239\n",
      "weight distance : 0.00220216991614\n",
      "Iteration 251 : Loss value 0.133732736653\n",
      "weight distance : 0.00219219277498\n",
      "Iteration 252 : Loss value 0.133669387549\n",
      "weight distance : 0.00218228937056\n",
      "Iteration 253 : Loss value 0.133606511701\n",
      "weight distance : 0.00217245891367\n",
      "Iteration 254 : Loss value 0.133544103959\n",
      "weight distance : 0.00216270062638\n",
      "Iteration 255 : Loss value 0.133482159246\n",
      "weight distance : 0.00215301374192\n",
      "Iteration 256 : Loss value 0.13342067256\n",
      "weight distance : 0.00214339750439\n",
      "Iteration 257 : Loss value 0.133359638969\n",
      "weight distance : 0.00213385116863\n",
      "Iteration 258 : Loss value 0.133299053614\n",
      "weight distance : 0.002124374\n",
      "Iteration 259 : Loss value 0.133238911704\n",
      "weight distance : 0.00211496527419\n",
      "Iteration 260 : Loss value 0.133179208515\n",
      "weight distance : 0.00210562427703\n",
      "Iteration 261 : Loss value 0.133119939391\n",
      "weight distance : 0.00209635030434\n",
      "Iteration 262 : Loss value 0.133061099743\n",
      "weight distance : 0.0020871426617\n",
      "Iteration 263 : Loss value 0.133002685044\n",
      "weight distance : 0.00207800066434\n",
      "Iteration 264 : Loss value 0.132944690832\n",
      "weight distance : 0.00206892363693\n",
      "Iteration 265 : Loss value 0.132887112706\n",
      "weight distance : 0.0020599109134\n",
      "Iteration 266 : Loss value 0.132829946328\n",
      "weight distance : 0.00205096183683\n",
      "Iteration 267 : Loss value 0.132773187419\n",
      "weight distance : 0.00204207575925\n",
      "Iteration 268 : Loss value 0.132716831759\n",
      "weight distance : 0.0020332520415\n",
      "Iteration 269 : Loss value 0.132660875186\n",
      "weight distance : 0.00202449005308\n",
      "Iteration 270 : Loss value 0.132605313597\n",
      "weight distance : 0.00201578917199\n",
      "Iteration 271 : Loss value 0.132550142942\n",
      "weight distance : 0.00200714878458\n",
      "Iteration 272 : Loss value 0.132495359229\n",
      "weight distance : 0.00199856828545\n",
      "Iteration 273 : Loss value 0.132440958518\n",
      "weight distance : 0.00199004707726\n",
      "Iteration 274 : Loss value 0.132386936923\n",
      "weight distance : 0.00198158457059\n",
      "Iteration 275 : Loss value 0.132333290612\n",
      "weight distance : 0.00197318018387\n",
      "Iteration 276 : Loss value 0.132280015802\n",
      "weight distance : 0.00196483334317\n",
      "Iteration 277 : Loss value 0.132227108762\n",
      "weight distance : 0.00195654348213\n",
      "Iteration 278 : Loss value 0.132174565811\n",
      "weight distance : 0.00194831004182\n",
      "Iteration 279 : Loss value 0.132122383317\n",
      "weight distance : 0.00194013247057\n",
      "Iteration 280 : Loss value 0.132070557694\n",
      "weight distance : 0.00193201022392\n",
      "Iteration 281 : Loss value 0.132019085408\n",
      "weight distance : 0.00192394276447\n",
      "Iteration 282 : Loss value 0.131967962966\n",
      "weight distance : 0.00191592956174\n",
      "Iteration 283 : Loss value 0.131917186924\n",
      "weight distance : 0.00190797009211\n",
      "Iteration 284 : Loss value 0.131866753884\n",
      "weight distance : 0.00190006383865\n",
      "Iteration 285 : Loss value 0.131816660491\n",
      "weight distance : 0.00189221029106\n",
      "Iteration 286 : Loss value 0.131766903432\n",
      "weight distance : 0.00188440894553\n",
      "Iteration 287 : Loss value 0.131717479439\n",
      "weight distance : 0.00187665930464\n",
      "Iteration 288 : Loss value 0.131668385286\n",
      "weight distance : 0.00186896087729\n",
      "Iteration 289 : Loss value 0.131619617788\n",
      "weight distance : 0.00186131317854\n",
      "Iteration 290 : Loss value 0.131571173802\n",
      "weight distance : 0.00185371572957\n",
      "Iteration 291 : Loss value 0.131523050223\n",
      "weight distance : 0.00184616805755\n",
      "Iteration 292 : Loss value 0.131475243988\n",
      "weight distance : 0.00183866969554\n",
      "Iteration 293 : Loss value 0.131427752071\n",
      "weight distance : 0.00183122018242\n",
      "Iteration 294 : Loss value 0.131380571486\n",
      "weight distance : 0.0018238190628\n",
      "Iteration 295 : Loss value 0.131333699283\n",
      "weight distance : 0.00181646588688\n",
      "Iteration 296 : Loss value 0.13128713255\n",
      "weight distance : 0.00180916021043\n",
      "Iteration 297 : Loss value 0.131240868413\n",
      "weight distance : 0.00180190159467\n",
      "Iteration 298 : Loss value 0.131194904031\n",
      "weight distance : 0.00179468960618\n",
      "Iteration 299 : Loss value 0.1311492366\n",
      "weight distance : 0.00178752381683\n",
      "Iteration 300 : Loss value 0.131103863351\n",
      "weight distance : 0.00178040380369\n",
      "Iteration 301 : Loss value 0.13105878155\n",
      "weight distance : 0.00177332914896\n",
      "Iteration 302 : Loss value 0.131013988495\n",
      "weight distance : 0.00176629943987\n",
      "Iteration 303 : Loss value 0.130969481518\n",
      "weight distance : 0.00175931426864\n",
      "Iteration 304 : Loss value 0.130925257985\n",
      "weight distance : 0.00175237323237\n",
      "Iteration 305 : Loss value 0.130881315292\n",
      "weight distance : 0.00174547593297\n",
      "Iteration 306 : Loss value 0.130837650869\n",
      "weight distance : 0.00173862197712\n",
      "Iteration 307 : Loss value 0.130794262176\n",
      "weight distance : 0.00173181097615\n",
      "Iteration 308 : Loss value 0.130751146703\n",
      "weight distance : 0.00172504254601\n",
      "Iteration 309 : Loss value 0.130708301973\n",
      "weight distance : 0.00171831630718\n",
      "Iteration 310 : Loss value 0.130665725536\n",
      "weight distance : 0.00171163188459\n",
      "Iteration 311 : Loss value 0.130623414973\n",
      "weight distance : 0.00170498890759\n",
      "Iteration 312 : Loss value 0.130581367894\n",
      "weight distance : 0.00169838700988\n",
      "Iteration 313 : Loss value 0.130539581937\n",
      "weight distance : 0.0016918258294\n",
      "Iteration 314 : Loss value 0.130498054769\n",
      "weight distance : 0.00168530500831\n",
      "Iteration 315 : Loss value 0.130456784084\n",
      "weight distance : 0.00167882419292\n",
      "Iteration 316 : Loss value 0.130415767603\n",
      "weight distance : 0.00167238303363\n",
      "Iteration 317 : Loss value 0.130375003074\n",
      "weight distance : 0.00166598118486\n",
      "Iteration 318 : Loss value 0.130334488272\n",
      "weight distance : 0.001659618305\n",
      "Iteration 319 : Loss value 0.130294220999\n",
      "weight distance : 0.00165329405635\n",
      "Iteration 320 : Loss value 0.130254199081\n",
      "weight distance : 0.00164700810506\n",
      "Iteration 321 : Loss value 0.130214420369\n",
      "weight distance : 0.0016407601211\n",
      "Iteration 322 : Loss value 0.130174882742\n",
      "weight distance : 0.00163454977815\n",
      "Iteration 323 : Loss value 0.1301355841\n",
      "weight distance : 0.00162837675361\n",
      "Iteration 324 : Loss value 0.13009652237\n",
      "weight distance : 0.00162224072851\n",
      "Iteration 325 : Loss value 0.130057695502\n",
      "weight distance : 0.00161614138745\n",
      "Iteration 326 : Loss value 0.130019101468\n",
      "weight distance : 0.00161007841858\n",
      "Iteration 327 : Loss value 0.129980738266\n",
      "weight distance : 0.00160405151355\n",
      "Iteration 328 : Loss value 0.129942603916\n",
      "weight distance : 0.00159806036742\n",
      "Iteration 329 : Loss value 0.129904696459\n",
      "weight distance : 0.00159210467865\n",
      "Iteration 330 : Loss value 0.12986701396\n",
      "weight distance : 0.00158618414903\n",
      "Iteration 331 : Loss value 0.129829554505\n",
      "weight distance : 0.00158029848368\n",
      "Iteration 332 : Loss value 0.129792316202\n",
      "weight distance : 0.00157444739092\n",
      "Iteration 333 : Loss value 0.129755297181\n",
      "weight distance : 0.0015686305823\n",
      "Iteration 334 : Loss value 0.129718495592\n",
      "weight distance : 0.00156284777253\n",
      "Iteration 335 : Loss value 0.129681909607\n",
      "weight distance : 0.00155709867944\n",
      "Iteration 336 : Loss value 0.129645537416\n",
      "weight distance : 0.0015513830239\n",
      "Iteration 337 : Loss value 0.129609377232\n",
      "weight distance : 0.00154570052986\n",
      "Iteration 338 : Loss value 0.129573427285\n",
      "weight distance : 0.00154005092421\n",
      "Iteration 339 : Loss value 0.129537685828\n",
      "weight distance : 0.00153443393684\n",
      "Iteration 340 : Loss value 0.129502151131\n",
      "weight distance : 0.00152884930049\n",
      "Iteration 341 : Loss value 0.129466821483\n",
      "weight distance : 0.00152329675083\n",
      "Iteration 342 : Loss value 0.129431695193\n",
      "weight distance : 0.00151777602631\n",
      "Iteration 343 : Loss value 0.129396770588\n",
      "weight distance : 0.0015122868682\n",
      "Iteration 344 : Loss value 0.129362046013\n",
      "weight distance : 0.00150682902051\n",
      "Iteration 345 : Loss value 0.129327519832\n",
      "weight distance : 0.00150140222999\n",
      "Iteration 346 : Loss value 0.129293190425\n",
      "weight distance : 0.00149600624605\n",
      "Iteration 347 : Loss value 0.129259056191\n",
      "weight distance : 0.00149064082076\n",
      "Iteration 348 : Loss value 0.129225115546\n",
      "weight distance : 0.00148530570879\n",
      "Iteration 349 : Loss value 0.129191366923\n",
      "weight distance : 0.0014800006674\n",
      "Iteration 350 : Loss value 0.129157808773\n",
      "weight distance : 0.00147472545637\n",
      "Iteration 351 : Loss value 0.129124439561\n",
      "weight distance : 0.00146947983801\n",
      "Iteration 352 : Loss value 0.129091257771\n",
      "weight distance : 0.00146426357711\n",
      "Iteration 353 : Loss value 0.129058261902\n",
      "weight distance : 0.00145907644088\n",
      "Iteration 354 : Loss value 0.129025450469\n",
      "weight distance : 0.00145391819897\n",
      "Iteration 355 : Loss value 0.128992822002\n",
      "weight distance : 0.00144878862338\n",
      "Iteration 356 : Loss value 0.128960375049\n",
      "weight distance : 0.00144368748849\n",
      "Iteration 357 : Loss value 0.12892810817\n",
      "weight distance : 0.00143861457099\n",
      "Iteration 358 : Loss value 0.128896019944\n",
      "weight distance : 0.00143356964984\n",
      "Iteration 359 : Loss value 0.128864108961\n",
      "weight distance : 0.00142855250629\n",
      "Iteration 360 : Loss value 0.128832373829\n",
      "weight distance : 0.0014235629238\n",
      "Iteration 361 : Loss value 0.128800813169\n",
      "weight distance : 0.00141860068805\n",
      "Iteration 362 : Loss value 0.128769425615\n",
      "weight distance : 0.00141366558688\n",
      "Iteration 363 : Loss value 0.128738209819\n",
      "weight distance : 0.00140875741028\n",
      "Iteration 364 : Loss value 0.128707164443\n",
      "weight distance : 0.00140387595036\n",
      "Iteration 365 : Loss value 0.128676288165\n",
      "weight distance : 0.00139902100133\n",
      "Iteration 366 : Loss value 0.128645579677\n",
      "weight distance : 0.00139419235946\n",
      "Iteration 367 : Loss value 0.128615037682\n",
      "weight distance : 0.00138938982307\n",
      "Iteration 368 : Loss value 0.1285846609\n",
      "weight distance : 0.00138461319248\n",
      "Iteration 369 : Loss value 0.12855444806\n",
      "weight distance : 0.00137986227002\n",
      "Iteration 370 : Loss value 0.128524397908\n",
      "weight distance : 0.00137513685995\n",
      "Iteration 371 : Loss value 0.128494509199\n",
      "weight distance : 0.00137043676852\n",
      "Iteration 372 : Loss value 0.128464780703\n",
      "weight distance : 0.00136576180385\n",
      "Iteration 373 : Loss value 0.128435211202\n",
      "weight distance : 0.00136111177598\n",
      "Iteration 374 : Loss value 0.128405799491\n",
      "weight distance : 0.00135648649683\n",
      "Iteration 375 : Loss value 0.128376544375\n",
      "weight distance : 0.00135188578012\n",
      "Iteration 376 : Loss value 0.128347444673\n",
      "weight distance : 0.00134730944145\n",
      "Iteration 377 : Loss value 0.128318499215\n",
      "weight distance : 0.00134275729819\n",
      "Iteration 378 : Loss value 0.128289706842\n",
      "weight distance : 0.00133822916948\n",
      "Iteration 379 : Loss value 0.12826106641\n",
      "weight distance : 0.00133372487626\n",
      "Iteration 380 : Loss value 0.128232576781\n",
      "weight distance : 0.00132924424116\n",
      "Iteration 381 : Loss value 0.128204236833\n",
      "weight distance : 0.00132478708855\n",
      "Iteration 382 : Loss value 0.128176045452\n",
      "weight distance : 0.0013203532445\n",
      "Iteration 383 : Loss value 0.128148001537\n",
      "weight distance : 0.00131594253673\n",
      "Iteration 384 : Loss value 0.128120103997\n",
      "weight distance : 0.00131155479465\n",
      "Iteration 385 : Loss value 0.128092351751\n",
      "weight distance : 0.00130718984927\n",
      "Iteration 386 : Loss value 0.128064743731\n",
      "weight distance : 0.00130284753324\n",
      "Iteration 387 : Loss value 0.128037278876\n",
      "weight distance : 0.00129852768079\n",
      "Iteration 388 : Loss value 0.128009956138\n",
      "weight distance : 0.00129423012773\n",
      "Iteration 389 : Loss value 0.127982774479\n",
      "weight distance : 0.00128995471145\n",
      "Iteration 390 : Loss value 0.12795573287\n",
      "weight distance : 0.00128570127083\n",
      "Iteration 391 : Loss value 0.127928830293\n",
      "weight distance : 0.00128146964633\n",
      "Iteration 392 : Loss value 0.127902065738\n",
      "weight distance : 0.00127725967987\n",
      "Iteration 393 : Loss value 0.127875438206\n",
      "weight distance : 0.00127307121489\n",
      "Iteration 394 : Loss value 0.127848946709\n",
      "weight distance : 0.00126890409626\n",
      "Iteration 395 : Loss value 0.127822590266\n",
      "weight distance : 0.00126475817034\n",
      "Iteration 396 : Loss value 0.127796367907\n",
      "weight distance : 0.0012606332849\n",
      "Iteration 397 : Loss value 0.127770278671\n",
      "weight distance : 0.00125652928913\n",
      "Iteration 398 : Loss value 0.127744321605\n",
      "weight distance : 0.00125244603364\n",
      "Iteration 399 : Loss value 0.127718495766\n",
      "weight distance : 0.0012483833704\n",
      "Iteration 400 : Loss value 0.12769280022\n",
      "weight distance : 0.00124434115277\n",
      "Iteration 401 : Loss value 0.127667234043\n",
      "weight distance : 0.00124031923545\n",
      "Iteration 402 : Loss value 0.127641796316\n",
      "weight distance : 0.00123631747449\n",
      "Iteration 403 : Loss value 0.127616486133\n",
      "weight distance : 0.00123233572726\n",
      "Iteration 404 : Loss value 0.127591302594\n",
      "weight distance : 0.00122837385241\n",
      "Iteration 405 : Loss value 0.127566244808\n",
      "weight distance : 0.00122443170994\n",
      "Iteration 406 : Loss value 0.127541311892\n",
      "weight distance : 0.00122050916107\n",
      "Iteration 407 : Loss value 0.127516502971\n",
      "weight distance : 0.00121660606831\n",
      "Iteration 408 : Loss value 0.12749181718\n",
      "weight distance : 0.00121272229543\n",
      "Iteration 409 : Loss value 0.127467253661\n",
      "weight distance : 0.00120885770742\n",
      "Iteration 410 : Loss value 0.127442811561\n",
      "weight distance : 0.00120501217048\n",
      "Iteration 411 : Loss value 0.12741849004\n",
      "weight distance : 0.00120118555205\n",
      "Iteration 412 : Loss value 0.127394288263\n",
      "weight distance : 0.00119737772073\n",
      "Iteration 413 : Loss value 0.127370205402\n",
      "weight distance : 0.00119358854633\n",
      "Iteration 414 : Loss value 0.127346240637\n",
      "weight distance : 0.00118981789981\n",
      "Iteration 415 : Loss value 0.127322393158\n",
      "weight distance : 0.00118606565328\n",
      "Iteration 416 : Loss value 0.127298662159\n",
      "weight distance : 0.00118233168002\n",
      "Iteration 417 : Loss value 0.127275046843\n",
      "weight distance : 0.00117861585439\n",
      "Iteration 418 : Loss value 0.12725154642\n",
      "weight distance : 0.00117491805192\n",
      "Iteration 419 : Loss value 0.127228160107\n",
      "weight distance : 0.00117123814921\n",
      "Iteration 420 : Loss value 0.127204887128\n",
      "weight distance : 0.00116757602397\n",
      "Iteration 421 : Loss value 0.127181726715\n",
      "weight distance : 0.00116393155497\n",
      "Iteration 422 : Loss value 0.127158678106\n",
      "weight distance : 0.00116030462207\n",
      "Iteration 423 : Loss value 0.127135740545\n",
      "weight distance : 0.00115669510618\n",
      "Iteration 424 : Loss value 0.127112913285\n",
      "weight distance : 0.00115310288925\n",
      "Iteration 425 : Loss value 0.127090195584\n",
      "weight distance : 0.00114952785427\n",
      "Iteration 426 : Loss value 0.127067586707\n",
      "weight distance : 0.00114596988525\n",
      "Iteration 427 : Loss value 0.127045085925\n",
      "weight distance : 0.0011424288672\n",
      "Iteration 428 : Loss value 0.127022692516\n",
      "weight distance : 0.00113890468615\n",
      "Iteration 429 : Loss value 0.127000405766\n",
      "weight distance : 0.00113539722911\n",
      "Iteration 430 : Loss value 0.126978224964\n",
      "weight distance : 0.00113190638408\n",
      "Iteration 431 : Loss value 0.126956149409\n",
      "weight distance : 0.00112843204001\n",
      "Iteration 432 : Loss value 0.126934178402\n",
      "weight distance : 0.00112497408682\n",
      "Iteration 433 : Loss value 0.126912311253\n",
      "weight distance : 0.00112153241539\n",
      "Iteration 434 : Loss value 0.126890547278\n",
      "weight distance : 0.0011181069175\n",
      "Iteration 435 : Loss value 0.126868885799\n",
      "weight distance : 0.0011146974859\n",
      "Iteration 436 : Loss value 0.126847326141\n",
      "weight distance : 0.00111130401423\n",
      "Iteration 437 : Loss value 0.126825867639\n",
      "weight distance : 0.00110792639707\n",
      "Iteration 438 : Loss value 0.126804509632\n",
      "weight distance : 0.00110456452986\n",
      "Iteration 439 : Loss value 0.126783251463\n",
      "weight distance : 0.00110121830895\n",
      "Iteration 440 : Loss value 0.126762092484\n",
      "weight distance : 0.00109788763157\n",
      "Iteration 441 : Loss value 0.126741032051\n",
      "weight distance : 0.00109457239583\n",
      "Iteration 442 : Loss value 0.126720069524\n",
      "weight distance : 0.00109127250068\n",
      "Iteration 443 : Loss value 0.126699204271\n",
      "weight distance : 0.00108798784593\n",
      "Iteration 444 : Loss value 0.126678435664\n",
      "weight distance : 0.00108471833225\n",
      "Iteration 445 : Loss value 0.126657763081\n",
      "weight distance : 0.00108146386113\n",
      "Iteration 446 : Loss value 0.126637185905\n",
      "weight distance : 0.00107822433489\n",
      "Iteration 447 : Loss value 0.126616703524\n",
      "weight distance : 0.00107499965666\n",
      "Iteration 448 : Loss value 0.126596315331\n",
      "weight distance : 0.0010717897304\n",
      "Iteration 449 : Loss value 0.126576020726\n",
      "weight distance : 0.00106859446085\n",
      "Iteration 450 : Loss value 0.126555819113\n",
      "weight distance : 0.00106541375355\n",
      "Iteration 451 : Loss value 0.126535709899\n",
      "weight distance : 0.00106224751483\n",
      "Iteration 452 : Loss value 0.126515692498\n",
      "weight distance : 0.00105909565179\n",
      "Iteration 453 : Loss value 0.12649576633\n",
      "weight distance : 0.00105595807231\n",
      "Iteration 454 : Loss value 0.126475930818\n",
      "weight distance : 0.00105283468502\n",
      "Iteration 455 : Loss value 0.12645618539\n",
      "weight distance : 0.0010497253993\n",
      "Iteration 456 : Loss value 0.126436529479\n",
      "weight distance : 0.00104663012529\n",
      "Iteration 457 : Loss value 0.126416962523\n",
      "weight distance : 0.00104354877385\n",
      "Iteration 458 : Loss value 0.126397483965\n",
      "weight distance : 0.00104048125659\n",
      "Iteration 459 : Loss value 0.126378093252\n",
      "weight distance : 0.00103742748583\n",
      "Iteration 460 : Loss value 0.126358789836\n",
      "weight distance : 0.00103438737461\n",
      "Iteration 461 : Loss value 0.126339573172\n",
      "weight distance : 0.00103136083668\n",
      "Iteration 462 : Loss value 0.126320442722\n",
      "weight distance : 0.00102834778649\n",
      "Iteration 463 : Loss value 0.126301397951\n",
      "weight distance : 0.00102534813918\n",
      "Iteration 464 : Loss value 0.126282438329\n",
      "weight distance : 0.00102236181059\n",
      "Iteration 465 : Loss value 0.126263563328\n",
      "weight distance : 0.00101938871723\n",
      "Iteration 466 : Loss value 0.126244772428\n",
      "weight distance : 0.00101642877629\n",
      "Iteration 467 : Loss value 0.126226065112\n",
      "weight distance : 0.00101348190562\n",
      "Iteration 468 : Loss value 0.126207440864\n",
      "weight distance : 0.00101054802374\n",
      "Iteration 469 : Loss value 0.126188899178\n",
      "weight distance : 0.00100762704982\n",
      "Iteration 470 : Loss value 0.126170439547\n",
      "weight distance : 0.00100471890367\n",
      "Iteration 471 : Loss value 0.126152061471\n",
      "weight distance : 0.00100182350576\n",
      "Iteration 472 : Loss value 0.126133764452\n",
      "weight distance : 0.000998940777182\n",
      "Iteration 473 : Loss value 0.126115547999\n",
      "weight distance : 0.000996070639654\n",
      "Iteration 474 : Loss value 0.126097411621\n",
      "weight distance : 0.000993213015526\n",
      "Iteration 475 : Loss value 0.126079354835\n",
      "weight distance : 0.000990367827759\n",
      "Iteration 476 : Loss value 0.126061377158\n",
      "weight distance : 0.000987534999927\n",
      "Iteration 477 : Loss value 0.126043478114\n",
      "weight distance : 0.000984714456208\n",
      "Iteration 478 : Loss value 0.126025657229\n",
      "weight distance : 0.000981906121379\n",
      "Iteration 479 : Loss value 0.126007914034\n",
      "weight distance : 0.00097910992081\n",
      "Iteration 480 : Loss value 0.125990248063\n",
      "weight distance : 0.000976325780457\n",
      "Iteration 481 : Loss value 0.125972658852\n",
      "weight distance : 0.000973553626861\n",
      "Iteration 482 : Loss value 0.125955145945\n",
      "weight distance : 0.000970793387135\n",
      "Iteration 483 : Loss value 0.125937708885\n",
      "weight distance : 0.000968044988965\n",
      "Iteration 484 : Loss value 0.125920347221\n",
      "weight distance : 0.000965308360601\n",
      "Iteration 485 : Loss value 0.125903060506\n",
      "weight distance : 0.000962583430853\n",
      "Iteration 486 : Loss value 0.125885848295\n",
      "weight distance : 0.000959870129086\n",
      "Iteration 487 : Loss value 0.125868710148\n",
      "weight distance : 0.000957168385213\n",
      "Iteration 488 : Loss value 0.125851645626\n",
      "weight distance : 0.000954478129691\n",
      "Iteration 489 : Loss value 0.125834654296\n",
      "weight distance : 0.000951799293515\n",
      "Iteration 490 : Loss value 0.125817735728\n",
      "weight distance : 0.000949131808214\n",
      "Iteration 491 : Loss value 0.125800889493\n",
      "weight distance : 0.000946475605846\n",
      "Iteration 492 : Loss value 0.125784115169\n",
      "weight distance : 0.000943830618992\n",
      "Iteration 493 : Loss value 0.125767412334\n",
      "weight distance : 0.000941196780751\n",
      "Iteration 494 : Loss value 0.12575078057\n",
      "weight distance : 0.000938574024736\n",
      "Iteration 495 : Loss value 0.125734219465\n",
      "weight distance : 0.000935962285069\n",
      "Iteration 496 : Loss value 0.125717728606\n",
      "weight distance : 0.000933361496376\n",
      "Iteration 497 : Loss value 0.125701307586\n",
      "weight distance : 0.000930771593781\n",
      "Iteration 498 : Loss value 0.125684956\n",
      "weight distance : 0.000928192512905\n",
      "Iteration 499 : Loss value 0.125668673446\n",
      "weight distance : 0.000925624189857\n",
      "Iteration 500 : Loss value 0.125652459526\n",
      "weight distance : 0.000923066561233\n",
      "Iteration 501 : Loss value 0.125636313845\n",
      "weight distance : 0.000920519564108\n",
      "Iteration 502 : Loss value 0.125620236009\n",
      "weight distance : 0.000917983136035\n",
      "Iteration 503 : Loss value 0.125604225629\n",
      "weight distance : 0.00091545721504\n",
      "Iteration 504 : Loss value 0.125588282319\n",
      "weight distance : 0.000912941739614\n",
      "Iteration 505 : Loss value 0.125572405694\n",
      "weight distance : 0.000910436648713\n",
      "Iteration 506 : Loss value 0.125556595375\n",
      "weight distance : 0.000907941881753\n",
      "Iteration 507 : Loss value 0.125540850982\n",
      "weight distance : 0.000905457378603\n",
      "Iteration 508 : Loss value 0.125525172142\n",
      "weight distance : 0.000902983079583\n",
      "Iteration 509 : Loss value 0.125509558481\n",
      "weight distance : 0.000900518925462\n",
      "Iteration 510 : Loss value 0.12549400963\n",
      "weight distance : 0.000898064857449\n",
      "Iteration 511 : Loss value 0.125478525223\n",
      "weight distance : 0.000895620817192\n",
      "Iteration 512 : Loss value 0.125463104895\n",
      "weight distance : 0.000893186746775\n",
      "Iteration 513 : Loss value 0.125447748286\n",
      "weight distance : 0.000890762588709\n",
      "Iteration 514 : Loss value 0.125432455036\n",
      "weight distance : 0.000888348285937\n",
      "Iteration 515 : Loss value 0.125417224789\n",
      "weight distance : 0.000885943781819\n",
      "Iteration 516 : Loss value 0.125402057193\n",
      "weight distance : 0.000883549020138\n",
      "Iteration 517 : Loss value 0.125386951896\n",
      "weight distance : 0.000881163945092\n",
      "Iteration 518 : Loss value 0.125371908551\n",
      "weight distance : 0.000878788501288\n",
      "Iteration 519 : Loss value 0.125356926811\n",
      "weight distance : 0.000876422633742\n",
      "Iteration 520 : Loss value 0.125342006334\n",
      "weight distance : 0.000874066287875\n",
      "Iteration 521 : Loss value 0.12532714678\n",
      "weight distance : 0.000871719409508\n",
      "Iteration 522 : Loss value 0.12531234781\n",
      "weight distance : 0.000869381944857\n",
      "Iteration 523 : Loss value 0.125297609088\n",
      "weight distance : 0.000867053840534\n",
      "Iteration 524 : Loss value 0.125282930283\n",
      "weight distance : 0.000864735043539\n",
      "Iteration 525 : Loss value 0.125268311062\n",
      "weight distance : 0.00086242550126\n",
      "Iteration 526 : Loss value 0.125253751097\n",
      "weight distance : 0.000860125161467\n",
      "Iteration 527 : Loss value 0.125239250063\n",
      "weight distance : 0.000857833972308\n",
      "Iteration 528 : Loss value 0.125224807637\n",
      "weight distance : 0.00085555188231\n",
      "Iteration 529 : Loss value 0.125210423496\n",
      "weight distance : 0.00085327884037\n",
      "Iteration 530 : Loss value 0.125196097323\n",
      "weight distance : 0.000851014795758\n",
      "Iteration 531 : Loss value 0.1251818288\n",
      "weight distance : 0.000848759698107\n",
      "Iteration 532 : Loss value 0.125167617613\n",
      "weight distance : 0.000846513497415\n",
      "Iteration 533 : Loss value 0.12515346345\n",
      "weight distance : 0.000844276144039\n",
      "Iteration 534 : Loss value 0.125139366001\n",
      "weight distance : 0.000842047588693\n",
      "Iteration 535 : Loss value 0.125125324958\n",
      "weight distance : 0.000839827782445\n",
      "Iteration 536 : Loss value 0.125111340017\n",
      "weight distance : 0.000837616676712\n",
      "Iteration 537 : Loss value 0.125097410873\n",
      "weight distance : 0.000835414223261\n",
      "Iteration 538 : Loss value 0.125083537227\n",
      "weight distance : 0.000833220374201\n",
      "Iteration 539 : Loss value 0.125069718777\n",
      "weight distance : 0.000831035081984\n",
      "Iteration 540 : Loss value 0.125055955229\n",
      "weight distance : 0.0008288582994\n",
      "Iteration 541 : Loss value 0.125042246287\n",
      "weight distance : 0.000826689979575\n",
      "Iteration 542 : Loss value 0.125028591658\n",
      "weight distance : 0.000824530075966\n",
      "Iteration 543 : Loss value 0.125014991051\n",
      "weight distance : 0.000822378542361\n",
      "Iteration 544 : Loss value 0.125001444179\n",
      "weight distance : 0.000820235332876\n",
      "Iteration 545 : Loss value 0.124987950754\n",
      "weight distance : 0.000818100401949\n",
      "Iteration 546 : Loss value 0.124974510493\n",
      "weight distance : 0.000815973704341\n",
      "Iteration 547 : Loss value 0.124961123111\n",
      "weight distance : 0.00081385519513\n",
      "Iteration 548 : Loss value 0.12494778833\n",
      "weight distance : 0.000811744829712\n",
      "Iteration 549 : Loss value 0.124934505869\n",
      "weight distance : 0.000809642563794\n",
      "Iteration 550 : Loss value 0.124921275453\n",
      "weight distance : 0.000807548353395\n",
      "Iteration 551 : Loss value 0.124908096807\n",
      "weight distance : 0.000805462154841\n",
      "Iteration 552 : Loss value 0.124894969657\n",
      "weight distance : 0.000803383924763\n",
      "Iteration 553 : Loss value 0.124881893733\n",
      "weight distance : 0.000801313620096\n",
      "Iteration 554 : Loss value 0.124868868765\n",
      "weight distance : 0.000799251198073\n",
      "Iteration 555 : Loss value 0.124855894487\n",
      "weight distance : 0.000797196616226\n",
      "Iteration 556 : Loss value 0.124842970632\n",
      "weight distance : 0.000795149832383\n",
      "Iteration 557 : Loss value 0.124830096938\n",
      "weight distance : 0.000793110804661\n",
      "Iteration 558 : Loss value 0.124817273141\n",
      "weight distance : 0.00079107949147\n",
      "Iteration 559 : Loss value 0.124804498983\n",
      "weight distance : 0.000789055851508\n",
      "Iteration 560 : Loss value 0.124791774206\n",
      "weight distance : 0.000787039843755\n",
      "Iteration 561 : Loss value 0.124779098551\n",
      "weight distance : 0.000785031427478\n",
      "Iteration 562 : Loss value 0.124766471765\n",
      "weight distance : 0.00078303056222\n",
      "Iteration 563 : Loss value 0.124753893596\n",
      "weight distance : 0.000781037207806\n",
      "Iteration 564 : Loss value 0.12474136379\n",
      "weight distance : 0.000779051324335\n",
      "Iteration 565 : Loss value 0.124728882099\n",
      "weight distance : 0.000777072872178\n",
      "Iteration 566 : Loss value 0.124716448275\n",
      "weight distance : 0.00077510181198\n",
      "Iteration 567 : Loss value 0.124704062072\n",
      "weight distance : 0.000773138104654\n",
      "Iteration 568 : Loss value 0.124691723245\n",
      "weight distance : 0.000771181711378\n",
      "Iteration 569 : Loss value 0.12467943155\n",
      "weight distance : 0.000769232593597\n",
      "Iteration 570 : Loss value 0.124667186748\n",
      "weight distance : 0.000767290713017\n",
      "Iteration 571 : Loss value 0.124654988597\n",
      "weight distance : 0.000765356031605\n",
      "Iteration 572 : Loss value 0.12464283686\n",
      "weight distance : 0.000763428511584\n",
      "Iteration 573 : Loss value 0.124630731301\n",
      "weight distance : 0.000761508115435\n",
      "Iteration 574 : Loss value 0.124618671684\n",
      "weight distance : 0.000759594805892\n",
      "Iteration 575 : Loss value 0.124606657776\n",
      "weight distance : 0.00075768854594\n",
      "Iteration 576 : Loss value 0.124594689345\n",
      "weight distance : 0.000755789298815\n",
      "Iteration 577 : Loss value 0.124582766161\n",
      "weight distance : 0.000753897028001\n",
      "Iteration 578 : Loss value 0.124570887995\n",
      "weight distance : 0.000752011697224\n",
      "Iteration 579 : Loss value 0.12455905462\n",
      "weight distance : 0.000750133270458\n",
      "Iteration 580 : Loss value 0.12454726581\n",
      "weight distance : 0.000748261711916\n",
      "Iteration 581 : Loss value 0.124535521341\n",
      "weight distance : 0.000746396986051\n",
      "Iteration 582 : Loss value 0.12452382099\n",
      "weight distance : 0.000744539057554\n",
      "Iteration 583 : Loss value 0.124512164535\n",
      "weight distance : 0.000742687891352\n",
      "Iteration 584 : Loss value 0.124500551758\n",
      "weight distance : 0.000740843452605\n",
      "Iteration 585 : Loss value 0.124488982438\n",
      "weight distance : 0.000739005706706\n",
      "Iteration 586 : Loss value 0.12447745636\n",
      "weight distance : 0.000737174619277\n",
      "Iteration 587 : Loss value 0.124465973307\n",
      "weight distance : 0.000735350156168\n",
      "Iteration 588 : Loss value 0.124454533066\n",
      "weight distance : 0.000733532283458\n",
      "Iteration 589 : Loss value 0.124443135423\n",
      "weight distance : 0.000731720967448\n",
      "Iteration 590 : Loss value 0.124431780167\n",
      "weight distance : 0.000729916174661\n",
      "Iteration 591 : Loss value 0.124420467089\n",
      "weight distance : 0.000728117871844\n",
      "Iteration 592 : Loss value 0.124409195979\n",
      "weight distance : 0.000726326025961\n",
      "Iteration 593 : Loss value 0.124397966629\n",
      "weight distance : 0.000724540604194\n",
      "Iteration 594 : Loss value 0.124386778835\n",
      "weight distance : 0.000722761573941\n",
      "Iteration 595 : Loss value 0.124375632391\n",
      "weight distance : 0.000720988902813\n",
      "Iteration 596 : Loss value 0.124364527093\n",
      "weight distance : 0.000719222558635\n",
      "Iteration 597 : Loss value 0.12435346274\n",
      "weight distance : 0.000717462509442\n",
      "Iteration 598 : Loss value 0.124342439132\n",
      "weight distance : 0.000715708723476\n",
      "Iteration 599 : Loss value 0.124331456067\n",
      "weight distance : 0.000713961169189\n",
      "Iteration 600 : Loss value 0.124320513348\n",
      "weight distance : 0.000712219815238\n",
      "Iteration 601 : Loss value 0.124309610779\n",
      "weight distance : 0.000710484630482\n",
      "Iteration 602 : Loss value 0.124298748163\n",
      "weight distance : 0.000708755583986\n",
      "Iteration 603 : Loss value 0.124287925306\n",
      "weight distance : 0.000707032645012\n",
      "Iteration 604 : Loss value 0.124277142014\n",
      "weight distance : 0.000705315783024\n",
      "Iteration 605 : Loss value 0.124266398096\n",
      "weight distance : 0.000703604967683\n",
      "Iteration 606 : Loss value 0.124255693361\n",
      "weight distance : 0.000701900168845\n",
      "Iteration 607 : Loss value 0.124245027618\n",
      "weight distance : 0.000700201356562\n",
      "Iteration 608 : Loss value 0.124234400681\n",
      "weight distance : 0.000698508501079\n",
      "Iteration 609 : Loss value 0.12422381236\n",
      "weight distance : 0.000696821572831\n",
      "Iteration 610 : Loss value 0.124213262471\n",
      "weight distance : 0.000695140542445\n",
      "Iteration 611 : Loss value 0.124202750829\n",
      "weight distance : 0.000693465380735\n",
      "Iteration 612 : Loss value 0.124192277249\n",
      "weight distance : 0.000691796058703\n",
      "Iteration 613 : Loss value 0.124181841549\n",
      "weight distance : 0.000690132547538\n",
      "Iteration 614 : Loss value 0.124171443547\n",
      "weight distance : 0.00068847481861\n",
      "Iteration 615 : Loss value 0.124161083064\n",
      "weight distance : 0.000686822843474\n",
      "Iteration 616 : Loss value 0.12415075992\n",
      "weight distance : 0.000685176593866\n",
      "Iteration 617 : Loss value 0.124140473937\n",
      "weight distance : 0.000683536041702\n",
      "Iteration 618 : Loss value 0.124130224937\n",
      "weight distance : 0.000681901159077\n",
      "Iteration 619 : Loss value 0.124120012746\n",
      "weight distance : 0.000680271918262\n",
      "Iteration 620 : Loss value 0.124109837188\n",
      "weight distance : 0.000678648291705\n",
      "Iteration 621 : Loss value 0.124099698089\n",
      "weight distance : 0.000677030252028\n",
      "Iteration 622 : Loss value 0.124089595276\n",
      "weight distance : 0.000675417772027\n",
      "Iteration 623 : Loss value 0.124079528579\n",
      "weight distance : 0.000673810824668\n",
      "Iteration 624 : Loss value 0.124069497827\n",
      "weight distance : 0.00067220938309\n",
      "Iteration 625 : Loss value 0.124059502849\n"
     ]
    }
   ],
   "source": [
    "model.initIteration();\n",
    "model.computeProb1();\n",
    "model.computeLoss();\n",
    "model.computeTestLoss()\n",
    "print ('Iteration 0 : Loss value ' + str(model.loss))\n",
    "\n",
    "\n",
    "#while (model.weightDist > 0.01 or model.iter<3):\n",
    "while (model.prevLoss - model.loss > model.thresh or model.iter<10):\n",
    "    model.prevLoss = model.loss;\n",
    "    model.iter = model.iter + 1;\n",
    "    temp = model.weights.copy();\n",
    "    \n",
    "    model.updateWeightsWhole(500)\n",
    "    model.computeProb1();\n",
    "        \n",
    "    model.computeLoss()\n",
    "    model.computeTestLoss()\n",
    "    model.distWeight(temp, model.weights)\n",
    "    print ('Iteration ' + str(model.iter) + ' : Loss value ' + str(model.loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.970166666667\n",
      "0 / 1 loss : [[ 0.02983333]]\n",
      "Loading data testing complete....\n",
      "Testing Data : Only looking at class 2!!!\n",
      "Accuracy : 0.9713\n",
      "0 / 1 loss : [[ 0.0287]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw83Pp9Dx/pkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10521fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.assess()\n",
    "model.load_data(\"testing\", testX, testY);\n",
    "model.makeY(2);\n",
    "model.assess()\n",
    "model.plotLoss('training loss', 'testing loss','binaryLoss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12360791726895808"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.testLossSet[model.iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
