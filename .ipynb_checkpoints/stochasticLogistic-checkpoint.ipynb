{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import mnist\n",
    "import scipy\n",
    "import scipy.sparse.linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import identity\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST loaded\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = mnist.load_mnist(\"training\", None, './MNIST');\n",
    "testX, testY = mnist.load_mnist(\"testing\", None, './MNIST');\n",
    "print(\"MNIST loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainX = trainX[0:100, :]\n",
    "#trainY = trainY[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logistic:\n",
    "    \n",
    "    \n",
    "    def __init__(self, eta, lamda, thresh):\n",
    "        self.eta = eta;\n",
    "        self.lamda = lamda;\n",
    "        self.thresh = thresh;\n",
    "        self.regularized = True;\n",
    "        \n",
    "    def load_data(self, string, ori_X, ori_Y):\n",
    "        \"\"\"\n",
    "        if string is \"training\":\n",
    "            ori_X, self.Y = mnist.load_mnist(\"training\", None, './MNIST');\n",
    "        elif string is \"testing\":\n",
    "            ori_X, self.Y = mnist.load_mnist(\"testing\", None, './MNIST');\n",
    "        \"\"\"\n",
    "        self.Y = ori_Y;\n",
    "        s = ori_X.shape;\n",
    "        self.d = s[1] * s[2] + 1;\n",
    "        self.n = self.d;\n",
    "        self.N = s[0];\n",
    "        self.X = np.reshape(ori_X, (self.N, self.d-1));\n",
    "        self.X = np.insert(self.X, 0, 1, axis=1);\n",
    "        self.X_sparse = csr_matrix(self.X, shape=(self.N, self.d))\n",
    "        print(\"Loading data \" + string + \" complete....\")\n",
    "        \n",
    "    def makeY(self, val):\n",
    "        temp = np.array(self.Y == val, dtype=float);\n",
    "        self.Y = np.reshape(temp, (self.N, 1))\n",
    "        self.Y_sparse = csr_matrix(self.Y, shape=(self.N, 1))\n",
    "        print(\"Only looking at class \" + str(val) + \"!!!\")\n",
    "    \n",
    "    def initIteration(self):\n",
    "        self.weights = np.zeros((self.n,1), dtype=float);\n",
    "        self.iter = 0;\n",
    "        self.prevLoss = 999999;\n",
    "            \n",
    "    def computeProb1(self):\n",
    "        temp = np.dot(self.X, self.weights);\n",
    "        temp[temp>100] = 100\n",
    "        temp = np.exp(temp);\n",
    "        self.prob1 = temp / (1 + temp)\n",
    "        self.sampleLoss = self.Y - self.prob1; \n",
    "        \n",
    "    def computeLoss(self):\n",
    "        #self.loss = np.sqrt(np.sum(self.sampleLoss * self.sampleLoss) / self.N)\n",
    "        lttemp = np.concatenate([np.float64(self.Y==0), np.float64(self.Y==1)], axis=1);\n",
    "        rttemp = np.concatenate([1-self.prob1, self.prob1], axis=1)\n",
    "        self.loss = -np.sum(np.log(np.sum(lttemp * rttemp, axis=1) + 0.0000001)) + self.lamda * np.sum(np.square(self.weights)); \n",
    "    \n",
    "    def updateWeights(self, curIdx, batchSize):\n",
    "        #print('Weight ' + str(curIdx) + ' : ' + str(self.weights[curIdx]))\n",
    "        self.batchSize = batchSize;\n",
    "        idx_from = range(0, self.N, self.batchSize)\n",
    "        idx_to = idx_from[1:]\n",
    "        idx_to.extend([self.N])\n",
    "        temp = self.weights;\n",
    "        if self.regularized:\n",
    "            for x in range(0, len(idx_from)):\n",
    "                self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[idx_from[x]:idx_to[x], curIdx] * self.sampleLoss[idx_from[x]:idx_to[x],0]);\n",
    "            self.weights[curIdx] = self.weights[curIdx] - self.eta * self.weights[curIdx] * self.lamda;\n",
    "            #self.weights[curIdx] = self.weights[curIdx] + self.eta * (np.sum(self.X[:, curIdx] * self.sampleLoss[:,0]) - self.weights[curIdx] * self.lamda);\n",
    "        else:\n",
    "            for x in range(0, len(idx_from)):\n",
    "                self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[idx_from[x]:idx_to[x], curIdx] * self.sampleLoss[idx_from[x]:idx_to[x],0]);\n",
    "            #self.weights[curIdx] = self.weights[curIdx] + self.eta * np.sum(self.X[:, curIdx] * self.sampleLoss[:,0]);\n",
    "        #print('Weight ' + str(curIdx) + ' : ' + str(self.weights[curIdx]))\n",
    "    \n",
    "    def distWeight(self):\n",
    "        self.weightDist = scipy.linalg.norm(self.weights - temp);\n",
    "    \n",
    "    def updateWeightStochastic(self, curIdx, curSmp):\n",
    "        if self.regularized:\n",
    "            self.weights[curIdx] = self.weights[curIdx] + self.eta * (self.X[curSmp, curIdx] * self.sampleLoss[curSmp,0] - self.weights[curIdx] * self.lamda);\n",
    "        else:\n",
    "            self.weights[curIdx] = self.weights[curIdx] + self.eta * self.X[curSmp, curIdx] * self.sampleLoss[curSmp,0];\n",
    "    \n",
    "    def assess(self):\n",
    "        self.computeProb1();\n",
    "        self.pred = self.prob1 > 0.5;\n",
    "        self.correct = np.sum(np.int16(self.pred == (self.Y==1)))\n",
    "        self.overallAccu = np.float(self.correct) / np.float(self.N);\n",
    "        self.loss01 = sum(abs(self.pred - self.Y)) / self.N\n",
    "        print('Accuracy : ' + str(self.overallAccu))\n",
    "        print('0 / 1 loss : ' + str(self.loss01))\n",
    "    \n",
    "    def genGaussFeatWeight(self, n):\n",
    "        self.n = n;\n",
    "        self.weight = np.random.randn(self.d, self.n);\n",
    "    \n",
    "    def randGaussFeatConv(self):\n",
    "        self.X = np.dot(self.X, self.weight);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data training complete....\n",
      "Only looking at class 2!!!\n"
     ]
    }
   ],
   "source": [
    "model = logistic(0.1, 0.000001, 0.00001);\n",
    "model.load_data(\"training\", trainX, trainY);\n",
    "model.makeY(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : Loss value 41588.8188336\n",
      "Iteration 1 : Loss value 96033.6512385\n",
      "Iteration 2 : Loss value 96032.8078497\n",
      "Iteration 3 : Loss value 96032.3260955\n",
      "Iteration 4 : Loss value 50781.1611165\n",
      "Iteration 5 : Loss value 52742.3581499\n"
     ]
    }
   ],
   "source": [
    "model.initIteration();\n",
    "model.computeProb1();\n",
    "model.computeLoss()\n",
    "print ('Iteration 0 : Loss value ' + str(model.loss))\n",
    "\n",
    "while (model.prevLoss - model.loss > model.thresh or model.iter<3):\n",
    "    model.prevLoss = model.loss;\n",
    "    model.iter = model.iter + 1;\n",
    "    for curSmp in range(0, model.N):\n",
    "        for curIdx in range(0, model.n): \n",
    "            model.updateWeightStochastic(curIdx, curSmp)\n",
    "    model.computeProb1();\n",
    "    model.computeLoss()\n",
    "    print ('Iteration ' + str(model.iter) + ' : Loss value ' + str(model.loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.assess()\n",
    "model.load_data(\"testing\", testX, testY);\n",
    "model.makeY(2);\n",
    "model.assess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
